{
  "_from": "crawlee@^3.5.2",
  "_id": "crawlee@3.5.2",
  "_inBundle": false,
  "_integrity": "sha512-VXf2emV0IR4E580sds9XhJ/m7qtwPhFUQY/rUqJTj5pcs2B8xN3RHiRmdNiq8TyS5GSIVTdWoeub+cJU5TYBHA==",
  "_location": "/crawlee",
  "_phantomChildren": {
    "@crawlee/templates": "3.5.2",
    "ansi-colors": "4.1.3",
    "fs-extra": "11.1.1",
    "inquirer": "8.2.6",
    "tslib": "2.6.2",
    "yargonaut": "1.1.4",
    "yargs": "17.7.2"
  },
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "crawlee@^3.5.2",
    "name": "crawlee",
    "escapedName": "crawlee",
    "rawSpec": "^3.5.2",
    "saveSpec": null,
    "fetchSpec": "^3.5.2"
  },
  "_requiredBy": [
    "#USER",
    "/"
  ],
  "_resolved": "https://registry.npmjs.org/crawlee/-/crawlee-3.5.2.tgz",
  "_shasum": "7fe11e8f60b44f340151b1559744ea4a02b9dcff",
  "_spec": "crawlee@^3.5.2",
  "_where": "C:\\Users\\Saad\\Desktop\\Files\\Nodejs\\APIfy_Scraping",
  "author": {
    "name": "Apify",
    "email": "support@apify.com",
    "url": "https://apify.com"
  },
  "bin": {
    "crawlee": "cli.js"
  },
  "bugs": {
    "url": "https://github.com/apify/crawlee/issues"
  },
  "bundleDependencies": false,
  "contributors": [
    {
      "name": "Jan Curn",
      "email": "jan@apify.com"
    },
    {
      "name": "Marek Trunkat",
      "email": "marek@apify.com"
    },
    {
      "name": "Ondra Urban",
      "email": "ondra@apify.com"
    }
  ],
  "dependencies": {
    "@crawlee/basic": "^3.5.2",
    "@crawlee/browser": "^3.5.2",
    "@crawlee/browser-pool": "^3.5.2",
    "@crawlee/cheerio": "^3.5.2",
    "@crawlee/cli": "^3.5.2",
    "@crawlee/core": "^3.5.2",
    "@crawlee/http": "^3.5.2",
    "@crawlee/jsdom": "^3.5.2",
    "@crawlee/linkedom": "^3.5.2",
    "@crawlee/playwright": "^3.5.2",
    "@crawlee/puppeteer": "^3.5.2",
    "@crawlee/utils": "^3.5.2",
    "import-local": "^3.1.0",
    "tslib": "^2.4.0"
  },
  "deprecated": false,
  "description": "The scalable web crawling and scraping library for JavaScript/Node.js. Enables development of data extraction and web automation jobs (not only) with headless Chrome and Puppeteer.",
  "engines": {
    "node": ">=16.0.0"
  },
  "exports": {
    ".": {
      "import": "./index.mjs",
      "require": "./index.js",
      "types": "./index.d.ts"
    },
    "./package.json": "./package.json"
  },
  "gitHead": "37415788f3a019b1e1217016918ad0186a006394",
  "homepage": "https://crawlee.dev",
  "keywords": [
    "apify",
    "headless",
    "chrome",
    "puppeteer",
    "crawler",
    "scraper"
  ],
  "lerna": {
    "command": {
      "publish": {
        "assets": []
      }
    }
  },
  "license": "Apache-2.0",
  "main": "./index.js",
  "module": "./index.mjs",
  "name": "crawlee",
  "peerDependencies": {
    "playwright": "<= 2.x",
    "puppeteer": "<= 21.1"
  },
  "peerDependenciesMeta": {
    "playwright": {
      "optional": true
    },
    "puppeteer": {
      "optional": true
    }
  },
  "publishConfig": {
    "access": "public"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/apify/crawlee.git"
  },
  "scripts": {
    "build": "yarn clean && yarn compile && yarn copy",
    "clean": "rimraf ./dist",
    "compile": "tsc -p tsconfig.build.json && gen-esm-wrapper ./index.js ./index.mjs",
    "copy": "ts-node -T ../../scripts/copy.ts"
  },
  "types": "./index.d.ts",
  "version": "3.5.2"
}
